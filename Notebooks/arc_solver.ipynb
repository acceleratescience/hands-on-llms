{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221b2e35",
   "metadata": {},
   "source": [
    "Code to call the OpenAI API to call and solve visual puzzles (ConceptARC problems).\n",
    "\n",
    "https://github.com/victorvikram/ConceptARC/tree/main/MinimalTasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66cf57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import dotenv\n",
    "import os\n",
    "from rich import print as rprint # for making fancy outputs\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27376b08",
   "metadata": {},
   "source": [
    "Call ConceptARC solver. Start by creating a good system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c05e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an intelligent solver of puzzles.\"\n",
    "user_prompt = 'your job is to solve a puzzle. These are puzzles in json format. I have some training examples and a test example in ConceptARC. Please solve it. Here is the puzzle:  {\"train\":[{\"input\":[[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,4,0,0,0,0,0],[0,0,0,4,4,4,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,3,3,3,0,0,0,0],[0,0,0,3,3,3,0,0,0,0],[0,0,0,3,3,3,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0]],\"output\":[[0,4,0],[4,4,4]]},{\"input\":[[0,0,3,3,0,0,0,0],[0,0,3,3,0,0,0,0],[0,0,0,0,0,0,0,0],[0,4,0,4,0,0,0,0],[0,4,4,4,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]],\"output\":[[3,3],[3,3]]},{\"input\":[[0,0,0,0,0,0,0,0,0],[0,0,0,3,3,3,3,3,0],[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],[0,0,4,4,4,4,0,0,0],[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0]],\"output\":[[3,3,3,3,3]]},{\"input\":[[0,0,0,0,0,0,0,0],[0,0,0,4,0,0,0,0],[0,0,4,0,4,0,0,0],[0,0,0,4,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,3,3,3,3,0,0],[0,0,3,0,0,3,0,0],[0,0,0,3,3,0,0,0]],\"output\":[[0,4,0],[4,0,4],[0,4,0]]}],\"test\":[{\"input\":[[4,4,4,0,0,0],[4,4,4,0,0,0],[0,0,0,0,0,0],[0,0,3,0,0,0],[3,3,3,3,0,0],[0,0,0,0,0,0]],\"output\":[[4,4,4],[4,4,4]]},{\"input\":[[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[4,4,4,4,4,4,4,4,4,4],[3,3,3,3,3,3,3,3,3,3],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0]],\"output\":[[4,4,4,4,4,4,4,4,4,4]]},{\"input\":[[0,0,0,0,0],[0,3,3,3,0],[0,3,0,3,0],[0,3,3,3,0],[0,4,0,4,0],[4,0,4,0,4]],\"output\":[[3,3,3],[3,0,3],[3,3,3]]}]}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1a066",
   "metadata": {},
   "source": [
    "Solve the problem now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc06d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the test example in the provided JSON format, we need to identify the patterns from the training examples and apply them to the new test inputs. \n",
      "\n",
      "Here's a breakdown of how to approach the test cases:\n",
      "\n",
      "### Test Case 1:\n",
      "Input:\n",
      "```\n",
      "[\n",
      "    [4, 4, 4, 0, 0, 0],\n",
      "    [4, 4, 4, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 3, 0, 0, 0],\n",
      "    [3, 3, 3, 3, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0]\n",
      "]\n",
      "```\n",
      "### Pattern Observed:\n",
      "- The output seems to contain sections of `4`s which appear as vertical columns, similar to prior examples that had blocks of `4`s or `3`s.\n",
      "\n",
      "**Output**:\n",
      "```\n",
      "[\n",
      "    [4, 4, 4],\n",
      "    [4, 4, 4]\n",
      "]\n",
      "```\n",
      "\n",
      "### Test Case 2:\n",
      "Input:\n",
      "```\n",
      "[\n",
      "    [0,0,0,0,0,0,0,0,0,0],\n",
      "    [0,0,0,0,0,0,0,0,0,0],\n",
      "    [4,4,4,4,4,4,4,4,4,4],\n",
      "    [3,3,3,3,3,3,3,3,3,3],\n",
      "    [0,0,0,0,0,0,0,0,0,0],\n",
      "    [0,0,0,0,0,0,0,0,0,0],\n",
      "    [0,0,0,0,0,0,0,0,0,0],\n",
      "    [0,0,0,0,0,0,0,0,0,0],\n",
      "    [0,0,0,0,0,0,0,0,0,0],\n",
      "    [0,0,0,0,0,0,0,0,0,0]\n",
      "]\n",
      "```\n",
      "### Pattern Observed:\n",
      "- The output here includes a long continuous row of `4`s similar to other training examples.\n",
      "\n",
      "**Output**:\n",
      "```\n",
      "[\n",
      "    [4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "]\n",
      "```\n",
      "\n",
      "### Test Case 3:\n",
      "Input:\n",
      "```\n",
      "[\n",
      "    [0,0,0,0,0],\n",
      "    [0,3,3,3,0],\n",
      "    [0,3,0,3,0],\n",
      "    [0,3,3,3,0],\n",
      "    [0,4,0,4,0],\n",
      "    [4,0,4,0,4]\n",
      "]\n",
      "```\n",
      "### Pattern Observed:\n",
      "- The output consists of parts from the input that contain `3`s, showing distinct structures from previous training examples.\n",
      "\n",
      "**Output**:\n",
      "```\n",
      "[\n",
      "    [3, 3, 3],\n",
      "    [3, 0, 3],\n",
      "    [3, 3, 3]\n",
      "]\n",
      "```\n",
      "\n",
      "### Final consolidated output for the test cases:\n",
      "```json\n",
      "{\n",
      "    \"test\": [\n",
      "        {\n",
      "            \"input\": [\n",
      "                [4, 4, 4, 0, 0, 0],\n",
      "                [4, 4, 4, 0, 0, 0],\n",
      "                [0, 0, 0, 0, 0, 0],\n",
      "                [0, 0, 3, 0, 0, 0],\n",
      "                [3, 3, 3, 3, 0, 0],\n",
      "                [0, 0, 0, 0, 0, 0]\n",
      "            ],\n",
      "            \"output\": [[4, 4, 4], [4, 4, 4]]\n",
      "        },\n",
      "        {\n",
      "            \"input\": [\n",
      "                [0,0,0,0,0,0,0,0,0,0],\n",
      "                [0,0,0,0,0,0,0,0,0,0],\n",
      "                [4,4,4,4,4,4,4,4,4,4],\n",
      "                [3,3,3,3,3,3,3,3,3,3],\n",
      "                [0,0,0,0,0,0,0,0,0,0],\n",
      "                [0,0,0,0,0,0,0,0,0,0],\n",
      "                [0,0\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",  \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content) # print the response from the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904e0c7f",
   "metadata": {},
   "source": [
    "Use a vision model now to solve ConceptARC puzze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c1e424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\"You are an intelligent solver of puzzles.\",\n",
    "\"Your job is to solve a puzzle. The puzzle is given to you as an image\",\n",
    "\"and you need to provide the solution in JSON format.\",\n",
    "\"Please provide the solution in a clear and concise manner.\",\n",
    "\"Make sure to include all necessary details in the solution.\",\n",
    "\"Feel free to make any inferences you need to.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb15adb",
   "metadata": {},
   "source": [
    "Now call the OpenAI vision model API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f074d71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa1938d",
   "metadata": {},
   "source": [
    "function to encode the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "567d58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b96e06e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to image file\n",
    "image_path = \"img/puzzle.png\"\n",
    "\n",
    "def get_image_caption(image_path, prompt):\n",
    "  # Getting the base64 string\n",
    "  base64_image = encode_image(image_path)\n",
    "\n",
    "  headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "  }\n",
    "\n",
    "  payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "          {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "              \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 512\n",
    "  }\n",
    "\n",
    "  response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "  return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc1f16",
   "metadata": {},
   "source": [
    "Pass this to the solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc38e97",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'img/puzzle.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m caption = \u001b[43mget_image_caption\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCaption for the image:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m rprint(caption) \u001b[38;5;66;03m# print the caption\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_image_caption\u001b[39m\u001b[34m(image_path, prompt)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_image_caption\u001b[39m(image_path, prompt):\n\u001b[32m      5\u001b[39m   \u001b[38;5;66;03m# Getting the base64 string\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m   base64_image = \u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m   headers = {\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOPENAI_API_KEY\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m   }\n\u001b[32m     13\u001b[39m   payload = {\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m512\u001b[39m\n\u001b[32m     33\u001b[39m   }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mencode_image\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_image\u001b[39m(image_path):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image_file:\n\u001b[32m      3\u001b[39m         encoded_string = base64.b64encode(image_file.read()).decode(\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m encoded_string\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'img/puzzle.png'"
     ]
    }
   ],
   "source": [
    "caption = get_image_caption(image_path, prompt)\n",
    "print(\"Caption for the image:\")\n",
    "rprint(caption) # print the caption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
